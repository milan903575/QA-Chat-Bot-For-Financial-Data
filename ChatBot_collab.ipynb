{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe3696f672e5437fac6af6cf1724f81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a9b764fc4a94452aa7abc53012f68e5",
              "IPY_MODEL_5135fd35b9ee413d816ac739a9745b19",
              "IPY_MODEL_4849ca29363946d5a6f1bedb52dac783"
            ],
            "layout": "IPY_MODEL_46bfec0c6d8e469480f35a5396fecb44"
          }
        },
        "9a9b764fc4a94452aa7abc53012f68e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eadec4580b094454b5cad975747e301c",
            "placeholder": "​",
            "style": "IPY_MODEL_876d46b1b88143a28b4857f3e7382a17",
            "value": "Batches: 100%"
          }
        },
        "5135fd35b9ee413d816ac739a9745b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e59e6f344e4536b493d1d429935895",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23647c621d7e469e8477c4efdfd905fc",
            "value": 4
          }
        },
        "4849ca29363946d5a6f1bedb52dac783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e0b571ca2547af9cbf18efceba011a",
            "placeholder": "​",
            "style": "IPY_MODEL_49d210a1b6cc4157b6e35cbfdad15e3c",
            "value": " 4/4 [00:02&lt;00:00,  2.03it/s]"
          }
        },
        "46bfec0c6d8e469480f35a5396fecb44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eadec4580b094454b5cad975747e301c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876d46b1b88143a28b4857f3e7382a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26e59e6f344e4536b493d1d429935895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23647c621d7e469e8477c4efdfd905fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56e0b571ca2547af9cbf18efceba011a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d210a1b6cc4157b6e35cbfdad15e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OSb0rKalz_6",
        "outputId": "4f23d884-5c4e-4a82-dcc0-d7e841a7f3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pinecone-client[grpc] in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (2024.12.14)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (1.66.0)\n",
            "Requirement already satisfied: grpcio>=1.59.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (1.69.0)\n",
            "Requirement already satisfied: lz4>=3.1.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (4.4.3)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (0.0.7)\n",
            "Requirement already satisfied: protobuf<5.0,>=4.25 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (4.25.5)\n",
            "Requirement already satisfied: protoc-gen-openapiv2<0.0.2,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (0.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers sentence-transformers pinecone-client[grpc] pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, the required Python libraries are installed. These include:\n",
        "- `transformers` and `sentence-transformers` for natural language processing tasks.\n",
        "- `pinecone-client[grpc]` for interacting with Pinecone's vector database.\n",
        "- `pandas` for handling tabular data efficiently.\n",
        "\n",
        "These libraries provide the foundation for building the RAG (Retrieval-Augmented Generation) model and processing financial data.\n"
      ],
      "metadata": {
        "id": "86n2PfZpuViB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "QjqDyHRxl6Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell imports essential Python libraries:\n",
        "- `pandas`: Used for creating and manipulating tabular data.\n",
        "- `numpy`: Provides numerical computation capabilities, though not used directly in this script.\n",
        "- `SentenceTransformer`: Used for creating text embeddings.\n",
        "- `os` and `files`: Facilitate file handling and user uploads.\n",
        "\n",
        "These imports prepare the environment for subsequent operations like embedding generation and file uploads.\n"
      ],
      "metadata": {
        "id": "ost6s6msuamk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dummy P&L data for testing\n",
        "pl_data = {\n",
        "    \"Quarter\": [f\"Q{(i % 4) + 1} {2000 + (i // 4)}\" for i in range(100)],\n",
        "    \"Revenue\": [\n",
        "        150000 + (i * 30000) for i in range(100)\n",
        "    ],\n",
        "    \"Operating Expenses\": [\n",
        "        80000 + (i * 10000) for i in range(100)\n",
        "    ],\n",
        "    \"Net Income\": [\n",
        "        70000 + (i * 5000) for i in range(100)\n",
        "    ],\n",
        "    \"Gross Profit\": [\n",
        "        100000 + (i * 10000) for i in range(100)\n",
        "    ],\n",
        "    \"EBT (Earnings Before Tax)\": [\n",
        "        65000 + (i * 5000) for i in range(100)\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "# Find the maximum length of the lists in pl_data\n",
        "max_length = max(len(value) for value in pl_data.values())\n",
        "\n",
        "# Pad each list to the maximum length (if necessary)\n",
        "for key, value in pl_data.items():\n",
        "    while len(value) < max_length:\n",
        "        value.append(None)\n",
        "\n",
        "# Create the DataFrame\n",
        "pl_df = pd.DataFrame(pl_data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G4AkSmivmDdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell generates dummy Profit and Loss (P&L) data for testing purposes:\n",
        "- The dataset includes columns like `Quarter`, `Revenue`, `Operating Expenses`, `Net Income`, `Gross Profit`, and `EBT (Earnings Before Tax)`.\n",
        "- It generates data for 100 quarters, spanning 25 years.\n",
        "- Each column's values are calculated dynamically using mathematical expressions to simulate realistic financial data.\n",
        "\n",
        "The data is then stored in a pandas DataFrame (`pl_df`), which will be used for further processing, such as embedding generation and querying.\n"
      ],
      "metadata": {
        "id": "jmmO_1uHuh8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pc = Pinecone(api_key=\"pcsk_4FW6nc_KCvYDUXeMCUT6Cb3YCfANmRnmyiibejoKybbGSnzmyRQUzNpsEEjpY6Qk1nPjJM\")\n",
        "\n",
        "# Define index name and configuration\n",
        "index_name = \"financial-qa-index\"\n",
        "\n",
        "# Check if the index exists, if not, create it\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,  # Matches SentenceTransformer model output\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"Created index: {index_name}\")\n",
        "else:\n",
        "    print(f\"Index {index_name} already exists.\")\n",
        "\n",
        "# Connect to the index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(2)  # Allow time for index readiness\n",
        "\n",
        "# View index stats\n",
        "index_stats = index.describe_index_stats()\n",
        "print(\"Index Stats:\", index_stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZJmHbD0mPvz",
        "outputId": "5c82ecb7-05b7-498d-9862-3cb6666f332d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index financial-qa-index already exists.\n",
            "Index Stats: {'dimension': 384,\n",
            " 'index_fullness': 0.0,\n",
            " 'namespaces': {'': {'vector_count': 100}},\n",
            " 'total_vector_count': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell initializes and configures the Pinecone vector database:\n",
        "- A Pinecone client is initialized using an API key.\n",
        "- The index `financial-qa-index` is defined with a vector dimension of 384 (matching the SentenceTransformer output) and `cosine` similarity as the metric.\n",
        "- If the index does not already exist, it is created on the AWS cloud in the `us-east-1` region.\n",
        "\n",
        "Finally, the index connection is established, and its statistics are printed for verification.\n"
      ],
      "metadata": {
        "id": "NmAweQFuup9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the SentenceTransformer model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Add descriptions to the dataset\n",
        "pl_df['Description'] = pl_df.apply(\n",
        "    lambda row: f\"Quarter: {row['Quarter']}, Revenue: {row['Revenue']}, \"\n",
        "                f\"Operating Expenses: {row['Operating Expenses']}, \"\n",
        "                f\"Net Income: {row['Net Income']}, Gross Profit: {row['Gross Profit']}, \"\n",
        "                f\"EBT: {row['EBT (Earnings Before Tax)']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedding_model.encode(pl_df['Description'].tolist(), show_progress_bar=True)\n",
        "print(\"Generated Embeddings.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "fe3696f672e5437fac6af6cf1724f81d",
            "9a9b764fc4a94452aa7abc53012f68e5",
            "5135fd35b9ee413d816ac739a9745b19",
            "4849ca29363946d5a6f1bedb52dac783",
            "46bfec0c6d8e469480f35a5396fecb44",
            "eadec4580b094454b5cad975747e301c",
            "876d46b1b88143a28b4857f3e7382a17",
            "26e59e6f344e4536b493d1d429935895",
            "23647c621d7e469e8477c4efdfd905fc",
            "56e0b571ca2547af9cbf18efceba011a",
            "49d210a1b6cc4157b6e35cbfdad15e3c"
          ]
        },
        "id": "ahELHV1JfjnA",
        "outputId": "5e42f544-6d9b-41d8-ecc6-f27251235c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe3696f672e5437fac6af6cf1724f81d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell loads a pre-trained SentenceTransformer model (`all-MiniLM-L6-v2`) for embedding generation:\n",
        "- Each row of the P&L dataset is converted into a descriptive text format using the `apply` function.\n",
        "- The resulting descriptions are passed to the SentenceTransformer model to generate embeddings, which are numerical vector representations of the text.\n",
        "- These embeddings are essential for storing data in the Pinecone index and enabling efficient query retrieval.\n"
      ],
      "metadata": {
        "id": "tVlVRmK8uv4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add embeddings to the index\n",
        "vectors = [\n",
        "    {\"id\": str(i), \"values\": embeddings[i], \"metadata\": {\"text\": pl_df['Description'][i]}}\n",
        "    for i in range(len(embeddings))\n",
        "]\n",
        "\n",
        "index.upsert(vectors=vectors)\n",
        "print(f\"Inserted {len(vectors)} records into the index.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LolZGt9lmUxG",
        "outputId": "2d3136a3-d8d9-46ad-c013-a1bce90a8abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 100 records into the index.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is responsible for uploading the generated embeddings into the Pinecone vector database. The embeddings represent the financial data in a format suitable for similarity-based retrieval.\n",
        "\n",
        "1. **Prepare Vectors for Upload**:\n",
        "   - A list of dictionaries, `vectors`, is created where each dictionary represents a single embedding and its associated metadata.\n",
        "   - Each dictionary contains:\n",
        "     - **`id`**: A unique identifier for the vector (based on the row index of the financial data).\n",
        "     - **`values`**: The embedding vector generated for the financial data description.\n",
        "     - **`metadata`**: Additional context in the form of text descriptions of the corresponding financial data.\n",
        "\n",
        "2. **Upload Vectors to Pinecone**:\n",
        "   - The `index.upsert()` method uploads the list of vectors to the Pinecone index (`index`).\n",
        "   - Pinecone uses the embeddings to build a vector database for efficient similarity-based retrieval during query processing.\n",
        "\n",
        "3. **Output Confirmation**:\n",
        "   - After uploading the vectors, the code prints the total number of vectors successfully inserted into the index.\n",
        "\n",
        "**Purpose**:\n",
        "- This step ensures that the processed financial data (in vector form) is stored in Pinecone, enabling the Retrieval-Augmented Generation (RAG) system to fetch relevant context for user queries in subsequent steps.\n"
      ],
      "metadata": {
        "id": "GTlULsUjwhQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zfj-swKDuzVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize FLAN-T5 model for question answering\n",
        "qa_pipeline = pipeline('text2text-generation', model='google/flan-t5-base')\n",
        "\n",
        "# Function to retrieve relevant context\n",
        "def retrieve_relevant_context(query, top_k=5):\n",
        "    query_embedding = embedding_model.encode(query)  # Convert query to vector\n",
        "    search_results = index.query(\n",
        "        vector=query_embedding.tolist(),  # Ensure this is a list of floats\n",
        "        top_k=top_k,  # Number of results to retrieve\n",
        "        include_metadata=True  # Include metadata in the response\n",
        "    )\n",
        "    # Extract relevant context (text) from metadata\n",
        "    return [result['metadata']['text'] for result in search_results['matches']]\n",
        "\n",
        "# RAG QA function\n",
        "def rag_qa(query):\n",
        "    try:\n",
        "        # Retrieve context from Pinecone\n",
        "        context = retrieve_relevant_context(query)\n",
        "\n",
        "        # Prepare input for the FLAN-T5 model\n",
        "        input_text = f\"Context: {' '.join(context)} Question: {query}\"\n",
        "\n",
        "        # Get the answer from FLAN-T5 model\n",
        "        answer = qa_pipeline(input_text, max_length=100, truncation=True)\n",
        "\n",
        "        # Return the generated answer\n",
        "        return answer[0]['generated_text']\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOebnO-ZmYFn",
        "outputId": "f030f2e0-50f3-4c42-f90b-1d483d9f7182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell initializes the QA pipeline and defines the core logic for query-answer generation using a Retrieval-Augmented Generation (RAG) approach:\n",
        "\n",
        "1. **FLAN-T5 Model Initialization**:\n",
        "   - The `qa_pipeline` is created using the FLAN-T5 model (`google/flan-t5-base`), which is optimized for text-to-text generation tasks like question answering.\n",
        "\n",
        "2. **Context Retrieval**:\n",
        "   - The `retrieve_relevant_context` function queries the Pinecone index using a given user query.\n",
        "   - The query is first converted into an embedding vector using the SentenceTransformer model.\n",
        "   - The Pinecone index is searched for the `top_k` most relevant entries based on cosine similarity.\n",
        "   - The function extracts and returns the relevant text (metadata) associated with the matching entries.\n",
        "\n",
        "3. **Answer Generation**:\n",
        "   - The `rag_qa` function combines the retrieved context with the user query to construct a detailed input prompt for the FLAN-T5 model.\n",
        "   - The model generates an answer based on the input context and query, providing a concise response to the user's question.\n",
        "\n",
        "4. **Error Handling**:\n",
        "   - The `rag_qa` function includes error handling to gracefully report issues, such as query processing failures or model errors.\n",
        "\n",
        "This cell demonstrates the integration of retrieval (Pinecone) and generation (FLAN-T5), forming the backbone of the QA system for answering financial queries.\n"
      ],
      "metadata": {
        "id": "2xumWIafvkPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple queries test\n",
        "queries = [\n",
        "    \"What is the gross profit for Q3 2024.?\",\n",
        "    \"How do the net income and operating expances compare to Q1 2024\",\n",
        "    \"What is the historical trend in revenue per customer between 2015 and 2024?\",\n",
        "    \"How has the operating income changed from Q2 2015 to Q4 2020?\",\n",
        "    \"What was the percentage change in net income from Q1 2012 to Q1 2023?\",\n",
        "    \"Which quarter in 2019 had the highest gross profit, and how much was it?\",\n",
        "    \"Compare the net income growth in 2016 and 2017, and determine which year had higher growth.\",\n",
        "    \"How much did capital expenditures increase or decrease from Q2 2015 to Q2 2016?\",\n",
        "    \"What was the average EPS for all of 2022, and how does it compare to the EPS for Q1 2022?\",\n",
        "    \"What was the compound annual growth rate (CAGR) of revenue from Q1 2018 to Q1 2024?\",\n",
        "    \"What is the percentage of operating expenses to revenue for Q3 2020?\",\n",
        "    \"Which quarter had the highest operating expenses from 2000 to 2015, and what was the value?\",\n",
        "    \"If the EPS for Q2 2021 had grown by 10%, what would the new EPS have been?\",\n",
        "    \"Calculate the average revenue per quarter from Q1 2010 to Q4 2024 and compare it to the average revenue from 2005 to 2009.\",\n",
        "    \"What is the ratio of capital expenditures to revenue for Q3 2020?\",\n",
        "    \"In which quarter between 2010 and 2024 did net income grow by the highest percentage compared to the previous quarter?\",\n",
        "    \"If the company maintained its Q2 2024 revenue growth rate for the next 5 years, what would the projected revenue be for Q2 2029?\",\n",
        "    \"How much higher was the net income in Q4 2022 compared to Q4 2021, and what was the percentage increase?\",\n",
        "    \"Was there a significant difference in capital expenditures between 2017 and 2018, and what caused it?\",\n",
        "    \"Which quarter between 2005 and 2020 had the highest year-over-year EPS growth, and what was the exact growth percentage?\",\n",
        "    \"Calculate the rolling 4-quarter average revenue for Q1 2015 to Q4 2024 and explain the trends over time.\",\n",
        "    \"What is the cumulative net income for the years 2010 to 2015, and how does it compare to the cumulative revenue for the same period?\",\n",
        "    \"What would the company’s net income have been in Q4 2010 if operating expenses were reduced by 10%?\",\n",
        "    \"Compare the growth in revenue for the first half of 2022 (Q1 and Q2) to the first half of 2021, and provide both absolute and percentage growth.\",\n",
        "    \"What is the ratio of operating income to operating expenses for Q3 2023?\",\n",
        "    \"What was the average growth rate in EPS from 2015 to 2020?\",\n",
        "    \"How much capital expenditure would have been needed in Q2 2023 to maintain the company’s growth rate from Q2 2022?\",\n",
        "    \"What is the percentage change in net income from Q1 2021 to Q1 2023, adjusted for inflation?\",\n",
        "    \"Which quarter between 2000 and 2010 had the highest gross profit margin, and what was the value?\",\n",
        "    \"What is the correlation between revenue and capital expenditures from 2000 to 2024?\",\n",
        "    \"How much would the net income need to increase each quarter in 2024 to achieve a 15% year-over-year growth for the full year?\",\n",
        "    \"Which quarter had the highest year-over-year percentage increase in operating income between 2015 and 2020?\",\n",
        "    \"What is the total net income for the years 2000 to 2004, and how does it compare to the total operating expenses for the same period?\",\n",
        "    \"Compare the company’s EPS performance during the 2008 financial crisis (2008-2009) with the recovery period in 2010-2011.\",\n",
        "    \"What would have been the capital expenditures in Q1 2021 if the company reduced its spending by 5% from the previous quarter?\",\n",
        "    \"How did operating income change as a percentage of revenue from 2012 to 2017?\",\n",
        "    \"Which quarter had the highest EPS growth from Q1 2020 to Q4 2023?\",\n",
        "    \"What is the expected revenue growth in Q1 2025, based on the average growth rate in Q1 over the last 10 years?\",\n",
        "    \"What is the ratio of net income to revenue for Q2 2014?\",\n",
        "    \"How did the company’s operating income evolve from Q3 2000 to Q3 2010?\",\n",
        "    \"Compare the revenue and net income growth rates from 2005 to 2010, and explain any notable differences.\",\n",
        "    \"What is the total operating income for the years 2015 to 2020, and how does it compare to the total net income for the same period?\",\n",
        "    \"Which quarter had the steepest drop in gross profit margin between 2000 and 2024, and what caused it?\",\n",
        "    \"What is the variance of operating expenses for the years 2010 to 2020?\",\n",
        "    \"How would the company's total revenue change if net income increased by 15% year-over-year from 2024 to 2029?\",\n",
        "    \"What was the highest revenue achieved in a single quarter between 2000 and 2024, and how does it compare to the average revenue?\",\n",
        "    \"Which quarter had the largest difference between operating income and net income, and what caused it?\",\n",
        "    \"What is the trend in gross profit margin from 2010 to 2024, and what major events affected it?\",\n",
        "    \"What was the average revenue per employee in 2023, assuming headcount data is available?\",\n",
        "    \"What is the compound growth rate of capital expenditure between 2010 and 2023?\",\n",
        "    \"What is the highest expense category contributing to operating expenses between 2015 and 2025?\"\n",
        "    \"What was the highest year-over-year growth in gross profit between 2005 and 2024?\",\n",
        "    \"What was the lowest EPS recorded between 2000 and 2024, and which quarter was it?\",\n",
        "    \"What is the trend in operating margin from 2000 to 2024?\",\n",
        "    \"Which quarter had the highest revenue-to-expense ratio between 2000 and 2024?\",\n",
        "    \"What is the average quarterly growth rate in revenue over the past 5 years?\",\n",
        "    \"How much has the dividend payout ratio fluctuated from 2015 to 2024?\",\n",
        "    \"What percentage of total expenses was accounted for by marketing between 2015 and 2020?\",\n",
        "    \"How much revenue did the company generate per employee in 2022?\",\n",
        "    \"What is the historical trend of return on assets (ROA) between 2010 and 2024?\",\n",
        "    \"What was the highest quarter-over-quarter revenue growth rate in the last 10 years?\",\n",
        "    \"Compare the average gross profit in the first half of the year (H1) with the second half (H2) for 2020-2024.\",\n",
        "    \"How did interest expenses impact net income between 2018 and 2023?\",\n",
        "    \"Which year had the largest decline in operating margin between 2000 and 2024?\",\n",
        "    \"What is the average annual dividend growth rate from 2010 to 2024?\",\n",
        "    \"How did share buybacks affect the EPS between 2015 and 2024?\",\n",
        "    \"Which quarter in the last decade had the highest return on equity (ROE)?\",\n",
        "    \"What was the highest market capitalization achieved between 2000 and 2024?\",\n",
        "    \"How has the company’s debt-to-equity ratio evolved from 2010 to 2024?\",\n",
        "    \"What is the correlation between revenue and operating income from 2000 to 2024?\",\n",
        "    \"What was the quarterly revenue trend in 2020 compared to 2021 during the pandemic?\",\n",
        "    \"How much cash flow did the company generate in Q4 2023, and how does it compare to Q4 2022?\",\n",
        "    \"What was the highest growth rate in cash flow from operations between 2015 and 2024?\",\n",
        "    \"Which quarter had the steepest decline in revenue during the 2008 financial crisis?\",\n",
        "    \"What is the historical average dividend yield between 2010 and 2024?\",\n",
        "    \"How did foreign exchange (forex) impact revenue in 2023 compared to 2022?\",\n",
        "    \"Which quarter between 2015 and 2024 had the highest free cash flow (FCF)?\",\n",
        "    \"What is the average tax rate the company has paid between 2010 and 2024?\",\n",
        "    \"How did restructuring costs affect net income during the 2020 pandemic?\",\n",
        "    \"What is the compound annual growth rate (CAGR) of net income from 2000 to 2024?\",\n",
        "    \"What was the highest quarterly gross margin achieved from 2010 to 2024?\",\n",
        "    \"What is the percentage change in debt levels between 2015 and 2024?\",\n",
        "    \"Which quarter had the highest increase in R&D expenses between 2010 and 2024?\",\n",
        "    \"How much net income was retained as retained earnings between 2015 and 2024?\",\n",
        "    \"How did acquisitions impact the revenue trend from 2018 to 2024?\",\n",
        "    \"What is the average annual growth rate of cash flow from investing activities between 2015 and 2024?\",\n",
        "    \"What was the impact of inflation on operating expenses from 2020 to 2024?\",\n",
        "    \"What was the average interest coverage ratio between 2000 and 2024?\",\n",
        "    \"What is the correlation between capital expenditures and revenue growth from 2000 to 2024?\",\n",
        "    \"Which year between 2010 and 2020 had the highest net profit margin?\",\n",
        "    \"What was the impact of tax rate changes on EPS from 2015 to 2024?\",\n",
        "    \"How much cash did the company generate per share in 2022?\",\n",
        "    \"What is the cumulative gross profit between 2015 and 2024?\",\n",
        "    \"Which quarter had the highest net income margin between 2000 and 2024?\",\n",
        "    \"What is the long-term trend in dividend payouts compared to net income?\",\n",
        "    \"Which quarter between 2015 and 2020 had the highest increase in gross profit?\",\n",
        "    \"What is the total revenue generated between 2000 and 2024?\",\n",
        "    \"What is the average price-to-earnings (P/E) ratio for the last 10 years?\",\n",
        "    \"What was the average gross margin percentage during the pandemic years (2020-2022)?\",\n",
        "    \"What was the impact of capital expenditures on free cash flow from 2015 to 2024?\",\n",
        "    \"How much revenue growth was driven by new product launches between 2018 and 2024?\",\n",
        "    \"What was the impact of cost-cutting measures on operating income in 2023?\",\n",
        "    \"How much net income was generated by the top-performing segment in 2022?\",\n",
        "    \"Which product category contributed the most to revenue growth in 2023?\",\n",
        "    \"What was the impact of share dilution on EPS between 2015 and 2024?\",\n",
        "    \"How much revenue was generated from international markets between 2010 and 2024?\",\n",
        "    \"What was the average EBITDA margin from 2015 to 2024?\",\n",
        "    \"How much did the company’s total liabilities increase from 2010 to 2024?\",\n",
        "    \"What is the rolling 12-month average revenue for the last 5 years?\",\n",
        "    \"What was the impact of interest rate changes on net income between 2020 and 2024?\",\n",
        "    \"How did changes in commodity prices affect the cost of goods sold (COGS) from 2015 to 2024?\",\n",
        "    \"What was the largest percentage change in total assets between 2000 and 2024?\",\n",
        "    \"What is the ratio of free cash flow to net income for the past 10 years?\"\n",
        "]\n",
        "\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Response: {rag_qa(query)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5I6J58b6qKwV",
        "outputId": "dcb51aeb-3902-4474-8fa2-c3f91bfe1b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the gross profit for Q3 2024.?\n",
            "Response: 960000\n",
            "\n",
            "Query: How do the net income and operating expances compare to Q1 2024\n",
            "Response: Net income and operating expances are 205000 - 205000 = 5000.\n",
            "\n",
            "Query: What is the historical trend in revenue per customer between 2015 and 2024?\n",
            "Response: revenue per customer increased by 4%\n",
            "\n",
            "Query: How has the operating income changed from Q2 2015 to Q4 2020?\n",
            "Response: Revenue: 2040000\n",
            "\n",
            "Query: What was the percentage change in net income from Q1 2012 to Q1 2023?\n",
            "Response: .3\n",
            "\n",
            "Query: Which quarter in 2019 had the highest gross profit, and how much was it?\n",
            "Response: Q1\n",
            "\n",
            "Query: Compare the net income growth in 2016 and 2017, and determine which year had higher growth.\n",
            "Response: 2016\n",
            "\n",
            "Query: How much did capital expenditures increase or decrease from Q2 2015 to Q2 2016?\n",
            "Response: increase\n",
            "\n",
            "Query: What was the average EPS for all of 2022, and how does it compare to the EPS for Q1 2022?\n",
            "Response: 2700000\n",
            "\n",
            "Query: What was the compound annual growth rate (CAGR) of revenue from Q1 2018 to Q1 2024?\n",
            "Response: 2.2\n",
            "\n",
            "Query: What is the percentage of operating expenses to revenue for Q3 2020?\n",
            "Response: .4\n",
            "\n",
            "Query: Which quarter had the highest operating expenses from 2000 to 2015, and what was the value?\n",
            "Response: Q1 2015\n",
            "\n",
            "Query: If the EPS for Q2 2021 had grown by 10%, what would the new EPS have been?\n",
            "Response: 970000\n",
            "\n",
            "Query: Calculate the average revenue per quarter from Q1 2010 to Q4 2024 and compare it to the average revenue from 2005 to 2009.\n",
            "Response: The average revenue per quarter from Q1 2010 to Q4 2024 is 125000 / 3 = 6000. The average revenue per quarter from 2005 to 2009 is 125000 / 3 = 6000. The average revenue per quarter from 2005 to 2009 is 125000 / 3 = 6000. The average revenue per quarter from 2005 to 2009 is 125000 / 3 = 6000. The average revenue per quarter from 2005 to 2009 is 125000 / 3 = 6000\n",
            "\n",
            "Query: What is the ratio of capital expenditures to revenue for Q3 2020?\n",
            "Response: 2\n",
            "\n",
            "Query: In which quarter between 2010 and 2024 did net income grow by the highest percentage compared to the previous quarter?\n",
            "Response: Q1 2010\n",
            "\n",
            "Query: If the company maintained its Q2 2024 revenue growth rate for the next 5 years, what would the projected revenue be for Q2 2029?\n",
            "Response: 2700000\n",
            "\n",
            "Query: How much higher was the net income in Q4 2022 compared to Q4 2021, and what was the percentage increase?\n",
            "Response: 505000\n",
            "\n",
            "Query: Was there a significant difference in capital expenditures between 2017 and 2018, and what caused it?\n",
            "Response: revenue\n",
            "\n",
            "Query: Which quarter between 2005 and 2020 had the highest year-over-year EPS growth, and what was the exact growth percentage?\n",
            "Response: Q1 2006\n",
            "\n",
            "Query: Calculate the rolling 4-quarter average revenue for Q1 2015 to Q4 2024 and explain the trends over time.\n",
            "Response: Q1 2015 to Q4 2024: Q1 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024: Q4 2015 to Q4 2024:\n",
            "\n",
            "Query: What is the cumulative net income for the years 2010 to 2015, and how does it compare to the cumulative revenue for the same period?\n",
            "Response: 32000000\n",
            "\n",
            "Query: What would the company’s net income have been in Q4 2010 if operating expenses were reduced by 10%?\n",
            "Response: 1440000\n",
            "\n",
            "Query: Compare the growth in revenue for the first half of 2022 (Q1 and Q2) to the first half of 2021, and provide both absolute and percentage growth.\n",
            "Response: Absolute growth: 2550000.\n",
            "\n",
            "Query: What is the ratio of operating income to operating expenses for Q3 2023?\n",
            "Response: 1\n",
            "\n",
            "Query: What was the average growth rate in EPS from 2015 to 2020?\n",
            "Response: 2.2\n",
            "\n",
            "Query: How much capital expenditure would have been needed in Q2 2023 to maintain the company’s growth rate from Q2 2022?\n",
            "Response: 930000\n",
            "\n",
            "Query: What is the percentage change in net income from Q1 2021 to Q1 2023, adjusted for inflation?\n",
            "Response: .2\n",
            "\n",
            "Query: Which quarter between 2000 and 2010 had the highest gross profit margin, and what was the value?\n",
            "Response: Q1 2010\n",
            "\n",
            "Query: What is the correlation between revenue and capital expenditures from 2000 to 2024?\n",
            "Response: revenue: 960000\n",
            "\n",
            "Query: How much would the net income need to increase each quarter in 2024 to achieve a 15% year-over-year growth for the full year?\n",
            "Response: 680000\n",
            "\n",
            "Query: Which quarter had the highest year-over-year percentage increase in operating income between 2015 and 2020?\n",
            "Response: Q1 2014\n",
            "\n",
            "Query: What is the total net income for the years 2000 to 2004, and how does it compare to the total operating expenses for the same period?\n",
            "Response: 630000\n",
            "\n",
            "Query: Compare the company’s EPS performance during the 2008 financial crisis (2008-2009) with the recovery period in 2010-2011.\n",
            "Response: The 2008 financial crisis (2008-2009) had a higher EPS performance than the 2010-2011 recovery period.\n",
            "\n",
            "Query: What would have been the capital expenditures in Q1 2021 if the company reduced its spending by 5% from the previous quarter?\n",
            "Response: 920000\n",
            "\n",
            "Query: How did operating income change as a percentage of revenue from 2012 to 2017?\n",
            "Response: Operating Expenses: 570000, Operating Expenses: 620000, Net Income: 340000, Gross Profit: 640000, EBT: 335000 Quarter: Q4 2012, Revenue: 1680000, Operating Expenses: 590000, Operating Expenses: 620000, Net Income: 340000, Gross Profit: 610000, EBT: 320000 Quarter: Q3 2013, Revenue: 1770000, Operating\n",
            "\n",
            "Query: Which quarter had the highest EPS growth from Q1 2020 to Q4 2023?\n",
            "Response: Q4 2014\n",
            "\n",
            "Query: What is the expected revenue growth in Q1 2025, based on the average growth rate in Q1 over the last 10 years?\n",
            "Response: 2.25%\n",
            "\n",
            "Query: What is the ratio of net income to revenue for Q2 2014?\n",
            "Response: 35000\n",
            "\n",
            "Query: How did the company’s operating income evolve from Q3 2000 to Q3 2010?\n",
            "Response: Revenue: 1410000, Operating Expenses: 500000, Net Income: 280000, Gross Profit: 520000, EBT: 275000 Quarter: Q3 2008 Revenue: 1170000 Operating Expenses: 420000, Operating Expenses: 420000, Net Income: 240000, Gross Profit: 440000, EBT: 235000 Quarter: Q3 2008 Revenue: 1170000 Operating Expenses: 420000, Operating Exp\n",
            "\n",
            "Query: Compare the revenue and net income growth rates from 2005 to 2010, and explain any notable differences.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-1fec008cdeee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Query: {query}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: {rag_qa(query)}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-7afe8322f8ce>\u001b[0m in \u001b[0;36mrag_qa\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Get the answer from FLAN-T5 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Return the generated answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         if (\n\u001b[1;32m    169\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m             )\n\u001b[1;32m   1300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3252\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3254\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1892\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 )\n\u001b[1;32m   1123\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mdo_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             cross_attention_outputs = self.layer[1](\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    627\u001b[0m     ):\n\u001b[1;32m    628\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         attention_output = self.EncDecAttention(\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query Testing**:\n",
        "   - Multiple financial queries are tested to demonstrate the pipeline's capability to handle complex financial questions.\n",
        "   - Example questions include historical trends, percentage changes, and growth rates over specific periods.\n",
        "\n",
        "The responses are printed for each query, showcasing the pipeline's functionality."
      ],
      "metadata": {
        "id": "lnhoAyc0vqOM"
      }
    }
  ]
}